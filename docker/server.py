# docker/server.py
import os
import uvicorn
import tempfile
import torch
import logging
import time
import gc
import numpy as np
import soundfile as sf
import librosa
from scipy import signal
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from TTS.api import TTS
from contextlib import asynccontextmanager
from pathlib import Path


# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Vari√°vel global para o modelo
tts_model = None

# ========== FUN√á√ïES OTIMIZADAS (RECOMENDA√á√ïES CHATGPT) ==========

def preprocess_reference_audio(input_path: str, output_path: str) -> bool:
    """
    Pr√©-processa o √°udio de refer√™ncia para formato ideal do XTTS v2:
    - 16 kHz mono PCM
    - Normaliza√ß√£o de volume
    - Remo√ß√£o de ru√≠do b√°sica
    """
    try:
        # Carregar √°udio original
        audio, orig_sr = librosa.load(input_path, sr=None, mono=False)
        
        # Converter para mono se necess√°rio
        if audio.ndim > 1:
            audio = librosa.to_mono(audio)
        
        # Resample para 16 kHz (ideal para XTTS v2)
        if orig_sr != 16000:
            audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=16000)
        
        # Normaliza√ß√£o suave
        audio = audio / np.max(np.abs(audio)) * 0.8
        
        # Remo√ß√£o b√°sica de ru√≠do (filtro passa-alta leve)
        b, a = signal.butter(3, 80, btype='high', fs=16000)
        audio = signal.filtfilt(b, a, audio)
        
        # Salvar como 16-bit PCM
        sf.write(output_path, audio, 16000, subtype='PCM_16')
        
        logger.info(f"‚úÖ √Åudio de refer√™ncia processado: {orig_sr}Hz ‚Üí 16kHz mono")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro no pr√©-processamento: {e}")
        return False

def postprocess_generated_audio(input_path: str, output_path: str) -> bool:
    """
    P√≥s-processa o √°udio gerado:
    - Converte de 24kHz para 44.1kHz
    - Mono para est√©reo
    - Normaliza√ß√£o final
    """
    try:
        # Carregar √°udio gerado (normalmente 24kHz mono do XTTS v2)
        audio, sr = sf.read(input_path)
        
        logger.info(f"üìä √Åudio original: {sr}Hz, {audio.shape}")
        
        # Resample para 44.1kHz (qualidade padr√£o)
        if sr != 44100:
            audio = librosa.resample(audio, orig_sr=sr, target_sr=44100)
        
        # Converter para est√©reo
        if audio.ndim == 1:
            audio = np.column_stack([audio, audio])
        
        # Normaliza√ß√£o final suave
        max_val = np.max(np.abs(audio))
        if max_val > 0:
            audio = audio / max_val * 0.85
        
        # Salvar como 44.1kHz est√©reo 16-bit
        sf.write(output_path, audio, 44100, subtype='PCM_16')
        
        logger.info(f"‚úÖ √Åudio p√≥s-processado: 44.1kHz est√©reo")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro no p√≥s-processamento: {e}")
        return False

def cleanup_temp_files(file_paths: list):
    """Remove arquivos tempor√°rios de forma segura"""
    for path in file_paths:
        if path and os.path.exists(path):
            try:
                os.unlink(path)
                logger.debug(f"üóëÔ∏è Arquivo removido: {path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Falha ao remover {path}: {e}")

# ========== FUN√á√ïES ORIGINAIS (MANTIDAS PARA COMPATIBILIDADE) ==========

def validate_reference_audio(audio_path: str) -> dict:
    """Validar e analisar √°udio de refer√™ncia"""
    try:
        audio_data, sample_rate = sf.read(audio_path)
        
        # Converter para mono se necess√°rio
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
        
        duration = len(audio_data) / sample_rate
        rms = np.sqrt(np.mean(audio_data**2))
        
        # Valida√ß√µes
        if duration < 3.0:
            return {"valid": False, "error": "√Åudio de refer√™ncia muito curto (m√≠nimo 3s)"}
        
        if duration > 30.0:
            return {"valid": False, "error": "√Åudio de refer√™ncia muito longo (m√°ximo 30s)"}
        
        if rms < 0.01:
            return {"valid": False, "error": "√Åudio de refer√™ncia muito baixo (aumente o volume)"}
        
        return {
            "valid": True, 
            "duration": duration,
            "sample_rate": sample_rate,
            "rms": rms,
            "recommendations": get_audio_recommendations(duration, rms)
        }
        
    except Exception as e:
        return {"valid": False, "error": f"Erro ao analisar √°udio: {str(e)}"}

def get_audio_recommendations(duration: float, rms: float) -> list:
    """Gerar recomenda√ß√µes baseadas na an√°lise do √°udio"""
    recommendations = []
    
    if duration < 5:
        recommendations.append("Use √°udio mais longo (5-15s) para melhor qualidade")
    
    if rms < 0.05:
        recommendations.append("√Åudio muito baixo - use √°udio com voz mais forte")
    
    if rms > 0.3:
        recommendations.append("√Åudio pode estar muito alto - normalize o volume")
    
    return recommendations

def remove_silence_from_audio(audio_path: str, output_path: str) -> bool:
    """Remover sil√™ncios excessivos do √°udio gerado"""
    try:
        audio_data, sample_rate = sf.read(audio_path)
        
        # Par√¢metros para detec√ß√£o de sil√™ncio
        silence_threshold = 0.01
        min_silence_duration = 0.5  # segundos
        min_silence_samples = int(min_silence_duration * sample_rate)
        
        # Detectar segmentos n√£o-silenciosos
        audio_abs = np.abs(audio_data)
        non_silent_indices = audio_abs > silence_threshold
        
        # Encontrar in√≠cio e fim de segmentos de fala
        speech_segments = []
        in_speech = False
        start = 0
        
        for i, is_speech in enumerate(non_silent_indices):
            if is_speech and not in_speech:
                start = max(0, i - int(0.1 * sample_rate))  # Padding de 0.1s
                in_speech = True
            elif not is_speech and in_speech:
                end = min(len(audio_data), i + int(0.1 * sample_rate))  # Padding de 0.1s
                if end - start > min_silence_samples:
                    speech_segments.append((start, end))
                in_speech = False
        
        # Adicionar √∫ltimo segmento se necess√°rio
        if in_speech:
            speech_segments.append((start, len(audio_data)))
        
        # Concatenar segmentos com pausas menores
        if speech_segments:
            processed_audio = []
            for i, (start, end) in enumerate(speech_segments):
                processed_audio.append(audio_data[start:end])
                # Adicionar pausa curta entre segmentos (exceto no √∫ltimo)
                if i < len(speech_segments) - 1:
                    pause_samples = int(0.3 * sample_rate)  # 0.3s de pausa
                    processed_audio.append(np.zeros(pause_samples))
            
            final_audio = np.concatenate(processed_audio)
            sf.write(output_path, final_audio, sample_rate)
            logger.info(f"üéµ Sil√™ncios removidos: {len(audio_data)/sample_rate:.1f}s ‚Üí {len(final_audio)/sample_rate:.1f}s")
            return True
        else:
            # Se n√£o encontrar fala, manter original
            sf.write(output_path, audio_data, sample_rate)
            return False
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erro ao remover sil√™ncios: {e}")
        return False

def optimize_text_for_speech(text: str, language: str = "pt") -> str:
    """Otimizar texto para melhor s√≠ntese de voz"""
    # Adicionar pontua√ß√£o para pausas naturais
    text = text.strip()
    
    # Adicionar pontos finais se n√£o houver
    if not text.endswith(('.', '!', '?')):
        text += '.'
    
    # Substituir abrevia√ß√µes comuns (portugu√™s)
    if language == "pt":
        replacements = {
            ' dr ': ' doutor ',
            ' dra ': ' doutora ',
            ' prof ': ' professor ',
            ' sra ': ' senhora ',
            ' sr ': ' senhor ',
            'vc': 'voc√™',
            'pq': 'porque',
            'td': 'tudo',
            'tbm': 'tamb√©m'
        }
        text_lower = text.lower()
        for abbrev, full in replacements.items():
            text = text.replace(abbrev, full)
            text_lower = text_lower.replace(abbrev, full)
    
    return text

def get_character_limits() -> dict:
    """Limites de caracteres por idioma para XTTS"""
    return {
        "pt": 160,  # Portugu√™s - limite conservador para melhor qualidade
        "en": 250,  # Ingl√™s
        "es": 220,  # Espanhol
        "fr": 230,  # Franc√™s
        "de": 180,  # Alem√£o
        "it": 210,  # Italiano
        "pl": 190,  # Polon√™s
        "tr": 200,  # Turco
        "ru": 180,  # Russo
        "nl": 200,  # Holand√™s
        "cs": 190,  # Tcheco
        "ar": 150,  # √Årabe
        "zh": 100,  # Chin√™s
        "ja": 120,  # Japon√™s
        "hi": 150,  # Hindi
        "ko": 130   # Coreano
    }

def smart_text_split(text: str, language: str = "pt", max_chars: int = None) -> list:
    """Dividir texto inteligentemente respeitando limites por idioma"""
    limits = get_character_limits()
    if max_chars is None:
        max_chars = limits.get(language, 160)
    
    # Se texto est√° dentro do limite, retornar como est√°
    if len(text) <= max_chars:
        return [text]
    
    # Dividir por senten√ßas primeiro
    import re
    
    # Padr√µes de divis√£o por idioma
    sentence_patterns = {
        "pt": r'[.!?]+\s+',
        "en": r'[.!?]+\s+',
        "es": r'[.!?]+\s+',
        "fr": r'[.!?]+\s+',
        "de": r'[.!?]+\s+',
        "it": r'[.!?]+\s+',
    }
    
    pattern = sentence_patterns.get(language, r'[.!?]+\s+')
    sentences = re.split(pattern, text.strip())
    
    # Reagrupar senten√ßas em chunks menores que o limite
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
            
        # Adicionar pontua√ß√£o se n√£o houver
        if not sentence.endswith(('.', '!', '?')):
            sentence += '.'
        
        # Se senten√ßa sozinha j√° excede limite, dividir por v√≠rgulas
        if len(sentence) > max_chars:
            sub_parts = sentence.split(',')
            for part in sub_parts:
                part = part.strip()
                if len(part) > max_chars:
                    # Se ainda muito grande, dividir for√ßadamente
                    for i in range(0, len(part), max_chars - 10):
                        chunk_part = part[i:i + max_chars - 10].strip()
                        if chunk_part:
                            chunks.append(chunk_part + '.')
                else:
                    if len(current_chunk + part) > max_chars:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                        current_chunk = part + ', '
                    else:
                        current_chunk += part + ', '
        else:
            # Verificar se pode adicionar √† chunk atual
            test_chunk = current_chunk + sentence + ' '
            if len(test_chunk) > max_chars:
                # Salvar chunk atual e iniciar nova
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ' '
            else:
                current_chunk += sentence + ' '
    
    # Adicionar √∫ltima chunk se houver
    if current_chunk.strip():
        chunks.append(current_chunk.strip())
    
    # Garantir que nenhuma chunk excede o limite
    final_chunks = []
    for chunk in chunks:
        if len(chunk) > max_chars:
            # Divis√£o for√ßada como √∫ltimo recurso
            for i in range(0, len(chunk), max_chars - 10):
                sub_chunk = chunk[i:i + max_chars - 10].strip()
                if sub_chunk:
                    final_chunks.append(sub_chunk)
        else:
            final_chunks.append(chunk)
    
    logger.info(f"üìù Texto dividido em {len(final_chunks)} chunks (limite: {max_chars} chars)")
    for i, chunk in enumerate(final_chunks):
        logger.info(f"   Chunk {i+1}: {len(chunk)} chars - '{chunk[:50]}...'")
    
    return final_chunks

def concatenate_audio_chunks(chunk_paths: list, output_path: str, crossfade_duration: float = 0.1) -> bool:
    """Concatenar chunks de √°udio com crossfade suave"""
    try:
        if not chunk_paths:
            return False
        
        if len(chunk_paths) == 1:
            # Se apenas um chunk, copiar diretamente
            audio_data, sr = sf.read(chunk_paths[0])
            sf.write(output_path, audio_data, sr)
            return True
        
        # Carregar primeiro chunk
        final_audio, sr = sf.read(chunk_paths[0])
        
        crossfade_samples = int(crossfade_duration * sr)
        
        for chunk_path in chunk_paths[1:]:
            next_audio, next_sr = sf.read(chunk_path)
            
            if next_sr != sr:
                logger.warning(f"‚ö†Ô∏è Sample rates diferentes: {sr} vs {next_sr}")
                continue
            
            # Aplicar crossfade entre chunks
            if len(final_audio) > crossfade_samples and len(next_audio) > crossfade_samples:
                # Fade out no final do √°udio atual
                fade_out = np.linspace(1, 0, crossfade_samples)
                final_audio[-crossfade_samples:] *= fade_out
                
                # Fade in no in√≠cio do pr√≥ximo √°udio
                fade_in = np.linspace(0, 1, crossfade_samples)
                next_audio[:crossfade_samples] *= fade_in
                
                # Sobrepor as regi√µes de crossfade
                overlap_region = final_audio[-crossfade_samples:] + next_audio[:crossfade_samples]
                
                # Concatenar: √°udio atual (sem final) + overlap + pr√≥ximo √°udio (sem in√≠cio)
                final_audio = np.concatenate([
                    final_audio[:-crossfade_samples],
                    overlap_region,
                    next_audio[crossfade_samples:]
                ])
            else:
                # Se chunks muito pequenos, concatenar diretamente
                final_audio = np.concatenate([final_audio, next_audio])
        
        sf.write(output_path, final_audio, sr)
        logger.info(f"üîó {len(chunk_paths)} chunks concatenados com crossfade")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao concatenar chunks: {e}")
        return False

# ========== FUN√á√ïES ORIGINAIS DE CORRE√á√ÉO (MANTIDAS) ==========

def fix_audio_hoarseness(audio_path: str, output_path: str) -> bool:
    """Corrigir rouquid√£o no √°udio"""
    try:
        audio_data, sr = sf.read(audio_path)
        
        # Normalizar volume para evitar satura√ß√£o
        max_val = np.max(np.abs(audio_data))
        if max_val > 0:
            # Normalizar para 85% do m√°ximo para evitar clipping
            audio_data = audio_data * (0.85 / max_val)
        
        # Aplicar filtro passa-alta suave para reduzir ru√≠do baixo
        from scipy import signal
        
        # Filtro passa-alta em 80Hz para remover ru√≠do de fundo
        nyquist = sr / 2
        low_cutoff = 80 / nyquist
        
        if low_cutoff < 0.99:  # Verificar se frequ√™ncia √© v√°lida
            b, a = signal.butter(2, low_cutoff, btype='high')
            audio_data = signal.filtfilt(b, a, audio_data)
        
        # Suavizar picos que causam rouquid√£o
        # Detec√ß√£o de picos excessivos
        threshold = np.std(audio_data) * 3
        peaks = np.abs(audio_data) > threshold
        
        if np.any(peaks):
            # Suavizar apenas os picos detectados
            window_size = int(0.005 * sr)  # 5ms de janela
            for i in np.where(peaks)[0]:
                start = max(0, i - window_size // 2)
                end = min(len(audio_data), i + window_size // 2)
                if end > start:
                    # Aplicar suaviza√ß√£o gaussiana na regi√£o do pico
                    audio_data[start:end] = signal.savgol_filter(
                        audio_data[start:end], 
                        min(11, end - start) if (end - start) % 2 == 1 else min(10, end - start - 1), 
                        3
                    )
        
        # Compress√£o suave para uniformizar din√¢mica
        # Compressor simples: reduzir apenas volumes muito altos
        compression_threshold = 0.7
        compression_ratio = 0.6
        
        mask = np.abs(audio_data) > compression_threshold
        audio_data[mask] = np.sign(audio_data[mask]) * (
            compression_threshold + 
            (np.abs(audio_data[mask]) - compression_threshold) * compression_ratio
        )
        
        sf.write(output_path, audio_data, sr)
        logger.info("üéõÔ∏è Corre√ß√£o de rouquid√£o aplicada")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao corrigir rouquid√£o: {e}")
        return False

# ========== APP SETUP ==========

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    global tts_model
    logger.info("üöÄ Iniciando servidor Coqui TTS...")
    
    # Verifica√ß√£o detalhada de GPU
    logger.info(f"üîç PyTorch version: {torch.__version__}")
    logger.info(f"üîç CUDA compiled version: {torch.version.cuda}")
    logger.info(f"üîç CUDA available: {torch.cuda.is_available()}")
    logger.info(f"üîç CUDA device count: {torch.cuda.device_count()}")
    
    if torch.cuda.is_available():
        device = "cuda"
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"üì± Dispositivo: {device}")
        logger.info(f"üéÆ GPU: {gpu_name}")
        logger.info(f"üíæ VRAM Total: {gpu_memory:.1f}GB")
        
        # Teste simples de GPU
        try:
            test_tensor = torch.randn(10, 10).cuda()
            logger.info(f"‚úÖ Teste de GPU bem-sucedido")
            del test_tensor
            torch.cuda.empty_cache()
        except Exception as e:
            logger.error(f"‚ùå Erro no teste de GPU: {e}")
            device = "cpu"
    else:
        device = "cpu"
        logger.warning("‚ö†Ô∏è GPU n√£o dispon√≠vel - usando CPU")
        logger.info("üì± Dispositivo: cpu")
        
        # Dicas para resolver problema de GPU
        logger.info("üí° Para usar GPU:")
        logger.info("   - Certifique-se que nvidia-docker est√° instalado")
        logger.info("   - Use: docker run --gpus all ...")
        logger.info("   - Ou: nvidia-docker run ...")
    
    try:
        logger.info("üì• Carregando modelo XTTS-v2...")
        start_time = time.time()
        
        # For√ßar uso de GPU se dispon√≠vel
        use_gpu = torch.cuda.is_available()
        logger.info(f"üéØ Carregando modelo com GPU: {use_gpu}")
        
        # Carregar modelo com tratamento de erro melhorado
        tts_model = TTS(
            "tts_models/multilingual/multi-dataset/xtts_v2", 
            gpu=use_gpu
        )
        
        # Verificar se modelo foi carregado na GPU
        if use_gpu and hasattr(tts_model, 'synthesizer') and hasattr(tts_model.synthesizer, 'tts_model'):
            model_device = next(tts_model.synthesizer.tts_model.parameters()).device
            logger.info(f"üéØ Modelo carregado no dispositivo: {model_device}")
        
        load_time = time.time() - start_time
        logger.info(f"‚úÖ Modelo carregado em {load_time:.2f}s!")
        
        # Verificar se o modelo tem os m√©todos necess√°rios
        if not hasattr(tts_model, 'tts_to_file'):
            raise AttributeError("Modelo n√£o possui m√©todo tts_to_file")
            
    except Exception as e:
        logger.error(f"‚ùå Erro ao carregar modelo: {e}")
        logger.error(f"Tipo de erro: {type(e).__name__}")
        raise
    
    yield
    
    # Shutdown
    logger.info("üî• Desligando servidor...")
    if tts_model:
        del tts_model
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()

# Criar app FastAPI
app = FastAPI(
    title="Coqui TTS Server",
    description="Servidor de s√≠ntese de voz com XTTS-v2",
    version="2.0.0",
    lifespan=lifespan
)

# CORS para desenvolvimento
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {
        "message": "Coqui TTS Server", 
        "status": "running",
        "version": "2.0.0",
        "model": "XTTS-v2"
    }

@app.get("/health")
async def health_check():
    gpu_info = {}
    if torch.cuda.is_available():
        gpu_info = {
            "gpu_name": torch.cuda.get_device_name(0),
            "gpu_memory_used": f"{torch.cuda.memory_allocated(0) / 1024**3:.2f}GB",
            "gpu_memory_total": f"{torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB",
            "gpu_memory_free": f"{(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1024**3:.2f}GB"
        }
    
    return {
        "status": "healthy",
        "model_loaded": tts_model is not None,
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "gpu_info": gpu_info,
        "temp_dir": str(tempfile.gettempdir())
    }

# ========== ENDPOINT OTIMIZADO (RECOMENDA√á√ïES CHATGPT) ==========

@app.post("/generate")
async def generate_audio_v2(
    text: str = Form(..., description="Texto para sintetizar"),
    reference_audio: UploadFile = File(..., description="√Åudio de refer√™ncia"),
    language: str = Form("pt", description="C√≥digo do idioma"),
    # Par√¢metros otimizados para qualidade/estabilidade
    temperature: float = Form(0.75, description="Temperatura (0.65-0.85)"),
    length_penalty: float = Form(1.0, description="Penalidade de comprimento"),
    repetition_penalty: float = Form(8.0, description="Penalidade de repeti√ß√£o"),
    top_k: int = Form(20, description="Top-k sampling"),
    top_p: float = Form(0.70, description="Top-p sampling"),
    speed: float = Form(1.0, description="Velocidade da fala"),
    remove_silence: bool = Form(True, description="Remover sil√™ncios excessivos"),
):
    if not tts_model:
        raise HTTPException(status_code=503, detail="Modelo n√£o carregado")
    
    # Valida√ß√µes b√°sicas
    if not text.strip():
        raise HTTPException(status_code=400, detail="Texto vazio")
    
    if len(text) > 1000:
        raise HTTPException(status_code=400, detail="Texto muito longo")
    
    # Validar formato do arquivo
    allowed_extensions = ('.wav', '.mp3', '.flac', '.ogg', '.m4a')
    if not reference_audio.filename.lower().endswith(allowed_extensions):
        raise HTTPException(
            status_code=400, 
            detail=f"Formato n√£o suportado. Use: {', '.join(allowed_extensions)}"
        )
    
    # Validar par√¢metros otimizados
    if not (0.65 <= temperature <= 0.85):
        raise HTTPException(status_code=400, detail="Temperatura deve estar entre 0.65-0.85")
    
    if not (0.6 <= top_p <= 0.8):
        raise HTTPException(status_code=400, detail="Top-p deve estar entre 0.6-0.8")
    
    if not (10 <= top_k <= 40):
        raise HTTPException(status_code=400, detail="Top-k deve estar entre 10-40")
    
    start_time = time.time()
    ref_path = None
    processed_ref_path = None
    output_path = None
    final_path = None
    
    try:
        logger.info(f"üéµ TTS v2 Otimizado - Texto: {len(text)} chars, Idioma: {language}")
        
        # 1. Salvar √°udio de refer√™ncia original
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as ref_file:
            content = await reference_audio.read()
            ref_file.write(content)
            ref_path = ref_file.name
        
        # 2. Pr√©-processar √°udio de refer√™ncia para 16kHz mono
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as processed_ref_file:
            processed_ref_path = processed_ref_file.name
        
        if not preprocess_reference_audio(ref_path, processed_ref_path):
            raise HTTPException(status_code=400, detail="Falha no pr√©-processamento do √°udio de refer√™ncia")
        
        # 3. Otimizar texto para s√≠ntese
        optimized_text = optimize_text_for_speech(text, language)
        
        # 4. Dividir texto em chunks se necess√°rio
        char_limits = get_character_limits()
        char_limit = char_limits.get(language, 160)
        
        if len(optimized_text) > char_limit:
            text_chunks = smart_text_split(optimized_text, language, char_limit)
        else:
            text_chunks = [optimized_text]
        
        logger.info(f"üìù Texto dividido em {len(text_chunks)} chunks")
        
        # 5. Gerar √°udio para cada chunk
        chunk_paths = []
        
        for i, chunk_text in enumerate(text_chunks):
            logger.info(f"üé§ Processando chunk {i+1}/{len(text_chunks)}")
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as chunk_file:
                chunk_path = chunk_file.name
            
            # S√≠ntese com configura√ß√µes otimizadas
            tts_model.tts_to_file(
                text=chunk_text.strip(),
                speaker_wav=processed_ref_path,  # Usa √°udio pr√©-processado
                language=language,
                file_path=chunk_path,
                temperature=temperature,
                length_penalty=length_penalty,
                repetition_penalty=repetition_penalty,
                top_k=top_k,
                top_p=top_p,
                speed=speed,
                split_sentences=True if len(chunk_text) > 160 else False  # Split autom√°tico para textos longos
            )
            
            # Verificar se arquivo foi gerado corretamente
            if not os.path.exists(chunk_path) or os.path.getsize(chunk_path) == 0:
                logger.error(f"‚ùå Falha na gera√ß√£o do chunk {i+1}")
                continue
            
            chunk_paths.append(chunk_path)
            logger.info(f"‚úÖ Chunk {i+1} gerado")
        
        if not chunk_paths:
            raise HTTPException(status_code=500, detail="Falha na gera√ß√£o de todos os chunks")
        
        # 6. Concatenar chunks se houver m√∫ltiplos
        if len(chunk_paths) > 1:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as concat_file:
                concatenated_path = concat_file.name
            
            if concatenate_audio_chunks(chunk_paths, concatenated_path):
                # Limpar chunks individuais
                for chunk_path in chunk_paths:
                    try:
                        os.unlink(chunk_path)
                    except:
                        pass
                output_path = concatenated_path
                logger.info(f"üîó {len(chunk_paths)} chunks concatenados")
            else:
                # Se concatena√ß√£o falhou, usar primeiro chunk
                output_path = chunk_paths[0]
                # Limpar outros chunks
                for chunk_path in chunk_paths[1:]:
                    try:
                        os.unlink(chunk_path)
                    except:
                        pass
        else:
            output_path = chunk_paths[0]
        
        # 7. P√≥s-processar para 44.1kHz est√©reo
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as final_file:
            final_path = final_file.name
        
        if not postprocess_generated_audio(output_path, final_path):
            # Fallback: usar √°udio original se p√≥s-processamento falhar
            final_path = output_path
            logger.warning("‚ö†Ô∏è Usando √°udio sem p√≥s-processamento")
        
        # 8. Remover sil√™ncios se solicitado
        if remove_silence:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as silence_file:
                silence_path = silence_file.name
            
            if remove_silence_from_audio(final_path, silence_path):
                if final_path != output_path:  # S√≥ remove se n√£o for o original
                    os.unlink(final_path)
                final_path = silence_path
        
        # Verificar arquivo final
        if not os.path.exists(final_path) or os.path.getsize(final_path) == 0:
            raise HTTPException(status_code=500, detail="Falha na gera√ß√£o do √°udio")
        
        # Estat√≠sticas finais
        generation_time = time.time() - start_time
        file_size = os.path.getsize(final_path)
        
        try:
            final_audio, final_sr = sf.read(final_path)
            duration = len(final_audio) / final_sr
            logger.info(f"‚úÖ √Åudio v2 gerado em {generation_time:.2f}s - {duration:.1f}s @ {final_sr}Hz")
        except:
            logger.info(f"‚úÖ √Åudio v2 gerado em {generation_time:.2f}s - {file_size} bytes")
        
        return FileResponse(
            final_path,
            media_type="audio/wav",
            filename=f"tts_optimized_{int(time.time())}.wav",
            headers={
                "X-Generation-Time": str(round(generation_time, 2)),
                "X-File-Size": str(file_size),
                "X-Audio-Duration": str(round(duration, 2)) if 'duration' in locals() else "unknown",
                "X-Sample-Rate": str(final_sr) if 'final_sr' in locals() else "44100",
                "X-Text-Chunks": str(len(text_chunks)),
                "X-Optimized": "true",
                "X-Version": "v2"
            },
            background=lambda: cleanup_temp_files([final_path])
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro na s√≠ntese v2: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro na s√≠ntese: {str(e)}")
    
    finally:
        # Limpar arquivos tempor√°rios (exceto o final que ser√° enviado)
        cleanup_temp_files([ref_path, processed_ref_path, output_path])

# ========== ENDPOINT ORIGINAL (MANTIDO PARA COMPATIBILIDADE) ==========

@app.post("/generate_old")
async def generate_audio(
    text: str = Form(..., description="Texto para sintetizar"),
    reference_audio: UploadFile = File(..., description="√Åudio de refer√™ncia (.wav)"),
    language: str = Form("pt", description="C√≥digo do idioma"),
    temperature: float = Form(0.76, description="Temperatura (0.70-0.85) - mais baixa elimina rouquid√£o"),
    length_penalty: float = Form(1.0, description="Penalidade de comprimento"),
    repetition_penalty: float = Form(8.0, description="Penalidade de repeti√ß√£o (6.0-10.0)"),
    top_k: int = Form(30, description="Top-k sampling (menor = mais est√°vel)"),
    top_p: float = Form(0.75, description="Top-p sampling (menor = mais est√°vel)"),
    speed: float = Form(0.96, description="Velocidade da fala (0.9-1.1)"),
    enable_text_splitting: bool = Form(True, description="Dividir texto automaticamente"),
    remove_silence: bool = Form(True, description="Remover sil√™ncios excessivos"),
    fix_hoarseness: bool = Form(True, description="Corrigir rouquid√£o no √°udio"),
    max_chars_per_chunk: int = Form(0, description="M√°ximo de caracteres por chunk (0=autom√°tico)")
):
    """Endpoint original mantido para compatibilidade - use /generate_v2 para vers√£o otimizada"""
    if not tts_model:
        raise HTTPException(status_code=503, detail="Modelo n√£o carregado")
    
    # Valida√ß√µes b√°sicas
    if not reference_audio.filename:
        raise HTTPException(status_code=400, detail="Nome do arquivo de √°udio n√£o fornecido")
    
    allowed_extensions = ('.wav', '.mp3', '.flac', '.ogg')
    if not reference_audio.filename.lower().endswith(allowed_extensions):
        raise HTTPException(
            status_code=400, 
            detail=f"Formato de √°udio n√£o suportado. Use: {', '.join(allowed_extensions)}"
        )
    
    if len(text.strip()) == 0:
        raise HTTPException(status_code=400, detail="Texto n√£o pode estar vazio")
    
    if len(text) > 1000:
        raise HTTPException(status_code=400, detail="Texto muito longo (m√°ximo 1000 caracteres)")
    
    # Validar par√¢metros
    if not (0.70 <= temperature <= 0.85):
        raise HTTPException(status_code=400, detail="Temperatura deve estar entre 0.70 e 0.85")
    
    if not (6.0 <= repetition_penalty <= 10.0):
        raise HTTPException(status_code=400, detail="Repetition penalty deve estar entre 6.0 e 10.0")
    
    if not (0.9 <= speed <= 1.1):
        raise HTTPException(status_code=400, detail="Velocidade deve estar entre 0.9 e 1.1")
    
    if not (10 <= top_k <= 50):
        raise HTTPException(status_code=400, detail="Top-k deve estar entre 10 e 50")
    
    if not (0.65 <= top_p <= 0.85):
        raise HTTPException(status_code=400, detail="Top-p deve estar entre 0.65 e 0.85")
    
    ref_path = None
    
    try:
        logger.info(f"üéµ TTS Original - Texto: {len(text)} chars, Idioma: {language}, Temp: {temperature}")
        start_time = time.time()
        
        # Verificar limite de caracteres
        char_limits = get_character_limits()
        char_limit = char_limits.get(language, 160)
        if max_chars_per_chunk > 0:
            char_limit = min(char_limit, max_chars_per_chunk)
        
        # Otimizar texto para melhor s√≠ntese
        optimized_text = optimize_text_for_speech(text, language)
        
        # Dividir texto em chunks se necess√°rio
        if enable_text_splitting and len(optimized_text) > char_limit:
            text_chunks = smart_text_split(optimized_text, language, char_limit)
        else:
            text_chunks = [optimized_text]
        
        # Salvar √°udio de refer√™ncia temporariamente
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as ref_file:
            content = await reference_audio.read()
            ref_file.write(content)
            ref_path = ref_file.name
        
        # Validar √°udio de refer√™ncia
        validation = validate_reference_audio(ref_path)
        if not validation["valid"]:
            raise HTTPException(status_code=400, detail=f"√Åudio de refer√™ncia inv√°lido: {validation['error']}")
        
        logger.info(f"‚úÖ √Åudio de refer√™ncia v√°lido - Dura√ß√£o: {validation['duration']:.1f}s")
        
        # Processar cada chunk
        chunk_paths = []
        
        for i, chunk_text in enumerate(text_chunks):
            logger.info(f"üé§ Processando chunk {i+1}/{len(text_chunks)} ({len(chunk_text)} chars)")
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as chunk_file:
                chunk_path = chunk_file.name
            
            # S√≠ntese de voz
            tts_model.tts_to_file(
                text=chunk_text,
                speaker_wav=ref_path,
                language=language,
                file_path=chunk_path,
                temperature=temperature,
                length_penalty=length_penalty,
                repetition_penalty=repetition_penalty,
                top_k=top_k,
                top_p=top_p,
                speed=speed,
                split_sentences=False
            )
            
            # Verificar se arquivo foi gerado corretamente
            if not os.path.exists(chunk_path) or os.path.getsize(chunk_path) == 0:
                logger.error(f"‚ùå Falha na gera√ß√£o do chunk {i+1}")
                continue
            
            chunk_paths.append(chunk_path)
            logger.info(f"‚úÖ Chunk {i+1} gerado com sucesso")
        
        if not chunk_paths:
            raise HTTPException(status_code=500, detail="Falha na gera√ß√£o de todos os chunks")
        
        # Concatenar chunks se houver m√∫ltiplos
        if len(chunk_paths) > 1:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as concat_file:
                concatenated_path = concat_file.name
            
            if concatenate_audio_chunks(chunk_paths, concatenated_path):
                # Limpar chunks individuais
                for chunk_path in chunk_paths:
                    try:
                        os.unlink(chunk_path)
                    except:
                        pass
                current_path = concatenated_path
                logger.info(f"üîó {len(chunk_paths)} chunks concatenados")
            else:
                # Se concatena√ß√£o falhou, usar primeiro chunk
                current_path = chunk_paths[0]
                # Limpar outros chunks
                for chunk_path in chunk_paths[1:]:
                    try:
                        os.unlink(chunk_path)
                    except:
                        pass
        else:
            current_path = chunk_paths[0]
        
        # P√≥s-processamento
        processing_steps = []
        
        # Corrigir rouquid√£o se solicitado
        if fix_hoarseness:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as fixed_file:
                fixed_path = fixed_file.name
            
            if fix_audio_hoarseness(current_path, fixed_path):
                os.unlink(current_path)
                current_path = fixed_path
                processing_steps.append("rouquid√£o corrigida")
            else:
                os.unlink(fixed_path)
        
        # Remover sil√™ncios se solicitado
        if remove_silence:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as processed_file:
                processed_path = processed_file.name
            
            if remove_silence_from_audio(current_path, processed_path):
                os.unlink(current_path)
                current_path = processed_path
                processing_steps.append("sil√™ncios removidos")
            else:
                os.unlink(processed_path)
        
        # Verificar arquivo final
        if not os.path.exists(current_path) or os.path.getsize(current_path) == 0:
            raise HTTPException(status_code=500, detail="Falha na gera√ß√£o do √°udio final")
        
        generation_time = time.time() - start_time
        file_size = os.path.getsize(current_path)
        
        # Informa√ß√µes do √°udio gerado
        try:
            final_audio, final_sr = sf.read(current_path)
            final_duration = len(final_audio) / final_sr
            logger.info(f"‚úÖ √Åudio gerado em {generation_time:.2f}s - {len(text_chunks)} chunks - Dura√ß√£o: {final_duration:.1f}s")
            if processing_steps:
                logger.info(f"üéõÔ∏è P√≥s-processamento: {', '.join(processing_steps)}")
        except:
            logger.info(f"‚úÖ √Åudio gerado em {generation_time:.2f}s - {len(text_chunks)} chunks - Tamanho: {file_size} bytes")
        
        return FileResponse(
            current_path,
            media_type="audio/wav",
            filename=f"generated_{int(time.time())}.wav",
            headers={
                "X-Generation-Time": str(generation_time),
                "X-File-Size": str(file_size),
                "X-Audio-Duration": str(final_duration) if 'final_duration' in locals() else "unknown",
                "X-Text-Chunks": str(len(text_chunks)),
                "X-Processing-Steps": ",".join(processing_steps) if processing_steps else "none",
                "X-Character-Limit": str(char_limit),
                "X-Hoarseness-Fixed": "true" if fix_hoarseness else "false",
                "X-Version": "original"
            },
            background=lambda: os.unlink(current_path) if os.path.exists(current_path) else None
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro ao gerar √°udio: {str(e)}")
        logger.error(f"Tipo de erro: {type(e).__name__}")
        raise HTTPException(status_code=500, detail=f"Erro na s√≠ntese: {str(e)}")
    
    finally:
        # Limpar arquivo de refer√™ncia
        if ref_path and os.path.exists(ref_path):
            try:
                os.unlink(ref_path)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Falha ao remover arquivo de refer√™ncia {ref_path}: {e}")

# ========== OUTROS ENDPOINTS ==========

@app.get("/audio-tips")
async def get_audio_tips():
    """Dicas para melhorar a qualidade do √°udio"""
    return {
        "optimization_info": {
            "v2_improvements": [
                "Pr√©-processamento do √°udio de refer√™ncia para 16kHz mono (ideal para XTTS v2)",
                "P√≥s-processamento para 44.1kHz est√©reo (qualidade universal)",
                "Sample rate correto elimina problema de voz abafada",
                "Par√¢metros otimizados para estabilidade e clareza",
                "Workflow simplificado sem corre√ß√µes desnecess√°rias"
            ],
            "recommended_endpoint": "/generate_v2 (otimizado) vs /generate (original)"
        },
        "reference_audio_tips": [
            "Use √°udio de 5-15 segundos de dura√ß√£o",
            "Voz clara e bem articulada",
            "Sem ru√≠do de fundo ou eco",
            "Volume adequado (n√£o muito baixo/alto)",
            "Emo√ß√£o/energia desejada na voz",
            "Qualquer formato ser√° convertido para 16kHz mono automaticamente (v2)"
        ],
        "text_tips": [
            "Use pontua√ß√£o adequada (. ! ?)",
            "Evite texto muito longo (m√°x 1000 chars)",
            "Escreva n√∫meros por extenso (2023 ‚Üí dois mil e vinte e tr√™s)",
            "Evite abrevia√ß√µes (Dr ‚Üí Doutor)",
            "Use frases completas"
        ],
        "parameter_tips_v2": {
            "temperature": "0.65-0.85 (padr√£o 0.75) - controlado para estabilidade",
            "repetition_penalty": "8.0 (padr√£o) - evita repeti√ß√µes",
            "speed": "1.0 (padr√£o) - velocidade natural",
            "top_k": "20 (otimizado) - mais conservador que original",
            "top_p": "0.70 (otimizado) - melhor estabilidade"
        },
        "sample_rate_fix": {
            "problem": "XTTS v2 gera em 24kHz, mas se reproduzido como 44.1kHz soa abafado",
            "solution": "v2 converte automaticamente para 44.1kHz est√©reo",
            "benefit": "Som claro e compat√≠vel com todos os players"
        },
        "character_limits": get_character_limits(),
        "endpoints": {
            "/generate_v2": "Vers√£o otimizada com corre√ß√µes de sample rate",
            "/generate": "Vers√£o original (mantida para compatibilidade)"
        }
    }

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )